import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras import layers, models
import matplotlib.pyplot as plt
import os, json, time

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª
dataset_dir = "dataset"
model_dir = "models"
os.makedirs(model_dir, exist_ok=True)

model_path = os.path.join(model_dir, "mobilenet_finetuned.h5")
labels_path = os.path.join(model_dir, "class_names.json")
history_path = os.path.join(model_dir, "fine_tune_history.json")

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
img_height, img_width = 224, 224
batch_size = 32
epochs = 5  # Ø¹Ø¯Ø¯ Ø¯ÙˆØ±Ø§Øª fine-tuning

# ØªØ­Ù…ÙŠÙ„ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„ÙØ¦Ø§Øª
with open(labels_path, "r") as f:
    class_names = json.load(f)

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø¹ Augmentation + preprocess_input
datagen = ImageDataGenerator(
    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input,
    validation_split=0.2,
    rotation_range=20,
    zoom_range=0.1,
    width_shift_range=0.1,
    height_shift_range=0.1,
    horizontal_flip=True
)

train_generator = datagen.flow_from_directory(
    dataset_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='categorical',
    subset='training'
)

val_generator = datagen.flow_from_directory(
    dataset_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='categorical',
    subset='validation'
)

# Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø¹ MobileNetV2
base_model = MobileNetV2(input_shape=(img_height, img_width, 3),
                         include_top=False,
                         weights='imagenet')
base_model.trainable = True  # ğŸ”“ Unfreeze

model = models.Sequential([
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.Dense(256, activation='relu'),
    layers.Dropout(0.4),
    layers.Dense(len(class_names), activation='softmax')
])

# ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù…Ø¹Ø¯Ù„ ØªØ¹Ù„Ù… Ù…Ù†Ø®ÙØ¶
model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Ø§Ù„ØªØ¯Ø±ÙŠØ¨
print("ğŸ” Starting fine-tuning on MobileNetV2...")
start = time.time()
history = model.fit(train_generator, validation_data=val_generator, epochs=epochs)
end = time.time()

# Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
model.save(model_path)
print(f"âœ… Fine-tuned model saved to {model_path}")
print(f"ğŸ•’ Fine-tuning time: {end - start:.2f} seconds")

# Ø­ÙØ¸ Ø³Ø¬Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
with open(history_path, "w") as f:
    json.dump(history.history, f)

# Ø±Ø³Ù… Ù…Ù†Ø­Ù†Ù‰ Ø§Ù„Ø¯Ù‚Ø©
plt.figure(figsize=(10, 5))
plt.plot(history.history['accuracy'], label="Train Accuracy")
plt.plot(history.history['val_accuracy'], label="Val Accuracy")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.title("ğŸ“ˆ Fine-Tuned MobileNetV2 Accuracy")
plt.grid(True)
plt.legend()
plt.tight_layout()
plt.show()
